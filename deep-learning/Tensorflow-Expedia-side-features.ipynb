{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Expedia plus features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "\n",
    "from typing import Dict, Text\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../data/expedia/'\n",
    "\n",
    "def convert_date(date_col):\n",
    "    return (pd.to_datetime(date_col) - dt.datetime(1970,1,1)).dt.total_seconds()\n",
    "\n",
    "def create_tf_datasets(filename: str):\n",
    "        \n",
    "    df = pd.read_csv(data_dir + filename)\n",
    "    \n",
    "    # Convert date to unix timestamp\n",
    "    df['date_time'] = convert_date(df['date_time'])\n",
    "    \n",
    "    # Convert to bytes\n",
    "    df['user_id'] = [bytes(str(uid), 'utf-8') for uid in df['user_id']]\n",
    "    df['hotel_cluster'] = [bytes(str(uid), 'utf-8') for uid in df['hotel_cluster']]\n",
    "    \n",
    "    features = df.drop(['cnt', 'srch_ci', 'srch_co'], axis=1)\n",
    "    \n",
    "    # Create tf datasets\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features))) \n",
    "    hotels = tf.data.Dataset.from_tensor_slices([bytes(str(uid), 'utf-8') for uid in range(0, 99)])\n",
    "    \n",
    "    # Column selection\n",
    "    dataset = dataset.map(lambda x: {\n",
    "        \"hotel_cluster\": x[\"hotel_cluster\"],\n",
    "        \"user_id\": x[\"user_id\"],\n",
    "        \"is_package\" : x[\"is_package\"],\n",
    "    })\n",
    "    \n",
    "    return dataset, hotels, len(df)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'train_sample' # 'train_sample'\n",
    "\n",
    "dataset, hotels, n_records = create_tf_datasets(f'{filename}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hotel_cluster': b'15', 'is_package': 0, 'user_id': b'472333'}\n"
     ]
    }
   ],
   "source": [
    "for x in dataset.take(1).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'0', b'1', b'10', b'11', b'12', b'13', b'14', b'15', b'16', b'17'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ids = dataset.batch(1_000_000).map(lambda x: x[\"user_id\"])\n",
    "hotel_clusters = hotels.batch(1_000_000)\n",
    "\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))\n",
    "unique_hotel_clusters = np.unique(np.concatenate(list(hotel_clusters)))\n",
    "\n",
    "unique_hotel_clusters[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_package = np.concatenate(list(dataset.map(lambda x: x[\"is_package\"]).batch(100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Indicator columns and embedding columns never work on features directly\n",
    "\n",
    "https://keras.io/guides/preprocessing_layers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModel(tf.keras.Model):\n",
    "  \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.user_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary=unique_user_ids, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_user_ids) + 1, 32),\n",
    "        ])\n",
    "\n",
    "        self.package_encoder = (tf.keras\n",
    "                                .layers.experimental\n",
    "                                .preprocessing\n",
    "                                .CategoryEncoding(output_mode=\"binary\"))\n",
    "        \n",
    "        self.package_encoder.adapt(is_package)\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        return tf.concat([\n",
    "            self.user_embedding(inputs[\"user_id\"]),\n",
    "            self.package_encoder(inputs[\"is_package\"]),\n",
    "        ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Candidate tower\n",
    "class HotelClusterModel(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hotel_clusters = tf.keras.Sequential([\n",
    "          tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "          vocabulary=unique_hotel_clusters, mask_token=None),\n",
    "          tf.keras.layers.Embedding(len(unique_hotel_clusters) + 1, embedding_dimension)\n",
    "        ])\n",
    "        \n",
    "    def call(self, hotel_cluster):\n",
    "        return self.hotel_clusters(hotel_cluster) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimension = 32\n",
    "\n",
    "# top K categorical accuracy: how often the true candidate is in the top K candidates for a given query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpediaModel(tfrs.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hotel_cluster_model: tf.keras.Model = HotelClusterModel()\n",
    "                    \n",
    "        self.user_model: tf.keras.Model = tf.keras.Sequential([\n",
    "          UserModel(),\n",
    "          tf.keras.layers.Dense(32)\n",
    "        ])\n",
    "        \n",
    "        metrics = tfrs.metrics.FactorizedTopK(\n",
    "          candidates=hotels.batch(128).map(self.hotel_cluster_model)\n",
    "        )\n",
    "\n",
    "        self.task: tf.keras.layers.Layer = tfrs.tasks.Retrieval(\n",
    "          metrics=metrics\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "        # We pick out the user features and pass them into the user model.\n",
    "        user_embeddings = self.user_model({\n",
    "            \"user_id\": features[\"user_id\"],\n",
    "            \"is_package\": features[\"is_package\"],\n",
    "        })\n",
    "        # And pick out the movie features and pass them into the movie model,\n",
    "        # getting embeddings back.\n",
    "        positive_hotel_clusters = self.hotel_cluster_model(features['hotel_cluster'])\n",
    "\n",
    "        # The task computes the loss and the metrics.\n",
    "        return self.task(user_embeddings, positive_hotel_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ExpediaModel()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO timesplit\n",
    "tf.random.set_seed(42)\n",
    "shuffled = dataset.shuffle(n_records, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(int(0.9 * n_records))\n",
    "test = shuffled.skip(int(0.9* n_records)).take(int(0.1 * n_records))\n",
    "\n",
    "cached_train = train.batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'user_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'is_package': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'user_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'is_package': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "55/55 [==============================] - ETA: 0s - factorized_top_k: 0.3822 - factorized_top_k/top_1_categorical_accuracy: 0.0158 - factorized_top_k/top_5_categorical_accuracy: 0.0922 - factorized_top_k/top_10_categorical_accuracy: 0.1688 - factorized_top_k/top_50_categorical_accuracy: 0.6343 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 73091.8685 - regularization_loss: 0.0000e+00 - total_loss: 73091.8685WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'user_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'is_package': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "55/55 [==============================] - 36s 655ms/step - factorized_top_k: 0.3822 - factorized_top_k/top_1_categorical_accuracy: 0.0158 - factorized_top_k/top_5_categorical_accuracy: 0.0922 - factorized_top_k/top_10_categorical_accuracy: 0.1688 - factorized_top_k/top_50_categorical_accuracy: 0.6343 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 72986.4967 - regularization_loss: 0.0000e+00 - total_loss: 72986.4967 - val_factorized_top_k: 0.4061 - val_factorized_top_k/top_1_categorical_accuracy: 0.0235 - val_factorized_top_k/top_5_categorical_accuracy: 0.1220 - val_factorized_top_k/top_10_categorical_accuracy: 0.2077 - val_factorized_top_k/top_50_categorical_accuracy: 0.6771 - val_factorized_top_k/top_100_categorical_accuracy: 1.0000 - val_loss: 5602.6523 - val_regularization_loss: 0.0000e+00 - val_total_loss: 5602.6523\n",
      "Epoch 2/2\n",
      "55/55 [==============================] - 28s 507ms/step - factorized_top_k: 0.6690 - factorized_top_k/top_1_categorical_accuracy: 0.2153 - factorized_top_k/top_5_categorical_accuracy: 0.5414 - factorized_top_k/top_10_categorical_accuracy: 0.6576 - factorized_top_k/top_50_categorical_accuracy: 0.9307 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 64947.6705 - regularization_loss: 0.0000e+00 - total_loss: 64947.6705 - val_factorized_top_k: 0.3977 - val_factorized_top_k/top_1_categorical_accuracy: 0.0245 - val_factorized_top_k/top_5_categorical_accuracy: 0.1113 - val_factorized_top_k/top_10_categorical_accuracy: 0.1937 - val_factorized_top_k/top_50_categorical_accuracy: 0.6593 - val_factorized_top_k/top_100_categorical_accuracy: 1.0000 - val_loss: 6175.3623 - val_regularization_loss: 0.0000e+00 - val_total_loss: 6175.3623\n"
     ]
    }
   ],
   "source": [
    "fitted_model = model.fit(cached_train, \n",
    "          validation_data=cached_test,\n",
    "          validation_freq=1,\n",
    "          epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 111ms/step - factorized_top_k: 0.3977 - factorized_top_k/top_1_categorical_accuracy: 0.0245 - factorized_top_k/top_5_categorical_accuracy: 0.1113 - factorized_top_k/top_10_categorical_accuracy: 0.1937 - factorized_top_k/top_50_categorical_accuracy: 0.6593 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 31764.9893 - regularization_loss: 0.0000e+00 - total_loss: 31764.9893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'factorized_top_k': array([0.02446, 0.11132, 0.19366, 0.65928, 1.     ], dtype=float32),\n",
       " 'factorized_top_k/top_1_categorical_accuracy': 0.024460000917315483,\n",
       " 'factorized_top_k/top_5_categorical_accuracy': 0.11131999641656876,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 0.19366000592708588,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 0.659280002117157,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 1.0,\n",
       " 'loss': 6175.3623046875,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 6175.3623046875}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 accuracy: 0.11.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy = fitted_model.history[\"val_factorized_top_k/top_5_categorical_accuracy\"][-1]\n",
    "print(f\"Top-5 accuracy: {accuracy:.2f}.\")\n",
    "\n",
    "num_validation_runs = len(fitted_model.history[\"val_factorized_top_k/top_5_categorical_accuracy\"])\n",
    "epochs = [(x + 1)* 1 for x in range(num_validation_runs)]\n",
    "\n",
    "plt.plot(epochs, fitted_model.history[\"val_factorized_top_k/top_5_categorical_accuracy\"], label=\"simple model\")\n",
    "plt.title(\"Accuracy vs epoch\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"Top-5 accuracy\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "query_path = os.path.join('./models/', f\"{filename}_package_query_model\")\n",
    "model.user_model.save(query_path)\n",
    "\n",
    "candidate_path = os.path.join('./models/', f\"{filename}_package_candidate_model\")\n",
    "model.hotel_cluster_model.save(candidate_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "user_model = tf.keras.models.load_model(query_path)\n",
    "\n",
    "candidate_model = tf.keras.models.load_model(candidate_path)\n",
    "query_embedding = user_model(tf.constant([\"10\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brute Force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model that takes in raw query features, and\n",
    "index = tfrs.layers.ann.BruteForce(query_model=model.user_model)\n",
    "\n",
    "hotel_cluster_embeddings = hotels.batch(100).map(model.hotel_cluster_model)\n",
    "\n",
    "# recommends hotels from all hotel clusters.\n",
    "index.index(candidates=hotel_cluster_embeddings, \n",
    "            identifiers=hotels)\n",
    "\n",
    "prediction_file = 'test.csv' # train_sample.csv test.csv\n",
    "users_to_predict = pd.read_csv(data_dir + prediction_file)[['user_id', 'is_package']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'hotel_cluster': <tf.Tensor: shape=(), dtype=string, numpy=b'15'>,\n",
       "  'user_id': <tf.Tensor: shape=(), dtype=string, numpy=b'472333'>,\n",
       "  'is_package': <tf.Tensor: shape=(), dtype=int64, numpy=0>}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dataset.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'472333'], dtype=object)>, 'is_package': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "Recommendations for user 472333: [b'15' b'10' b'76']\n"
     ]
    }
   ],
   "source": [
    "_, hotel_cluster = index(queries={'user_id':tf.constant([\"472333\"]), \n",
    "                                   'is_package': tf.constant([1])})\n",
    "print(f\"Recommendations for user 472333: {hotel_cluster[0, :3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_package</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2528238</th>\n",
       "      <td>1198754</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2528239</th>\n",
       "      <td>1198758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2528240</th>\n",
       "      <td>1198771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2528241</th>\n",
       "      <td>1198775</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2528242</th>\n",
       "      <td>1198782</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2528243 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  is_package\n",
       "0              1           0\n",
       "1              1           0\n",
       "2             20           0\n",
       "3             28           1\n",
       "4             50           0\n",
       "...          ...         ...\n",
       "2528238  1198754           0\n",
       "2528239  1198758           0\n",
       "2528240  1198771           0\n",
       "2528241  1198775           0\n",
       "2528242  1198782           0\n",
       "\n",
       "[2528243 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_to_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 0 users.\n",
      "Parsed 1000 users.\n",
      "Parsed 2000 users.\n",
      "Parsed 3000 users.\n",
      "Parsed 4000 users.\n",
      "Parsed 5000 users.\n",
      "Parsed 6000 users.\n",
      "Parsed 7000 users.\n",
      "Parsed 8000 users.\n",
      "Parsed 9000 users.\n",
      "Parsed 10000 users.\n",
      "Parsed 11000 users.\n",
      "Parsed 12000 users.\n",
      "Parsed 13000 users.\n",
      "Parsed 14000 users.\n",
      "Parsed 15000 users.\n",
      "Parsed 16000 users.\n",
      "Parsed 17000 users.\n",
      "Parsed 18000 users.\n",
      "Parsed 19000 users.\n",
      "Parsed 20000 users.\n",
      "Parsed 21000 users.\n",
      "Parsed 22000 users.\n",
      "Parsed 23000 users.\n",
      "Parsed 24000 users.\n",
      "Parsed 25000 users.\n",
      "Parsed 26000 users.\n",
      "Parsed 27000 users.\n",
      "Parsed 28000 users.\n",
      "Parsed 29000 users.\n",
      "Parsed 30000 users.\n",
      "Parsed 31000 users.\n",
      "Parsed 32000 users.\n",
      "Parsed 33000 users.\n",
      "Parsed 34000 users.\n",
      "Parsed 35000 users.\n",
      "Parsed 36000 users.\n",
      "Parsed 37000 users.\n",
      "Parsed 38000 users.\n",
      "Parsed 39000 users.\n",
      "Parsed 40000 users.\n",
      "Parsed 41000 users.\n",
      "Parsed 42000 users.\n",
      "Parsed 43000 users.\n",
      "Parsed 44000 users.\n",
      "Parsed 45000 users.\n",
      "Parsed 46000 users.\n",
      "Parsed 47000 users.\n",
      "Parsed 48000 users.\n",
      "Parsed 49000 users.\n",
      "Parsed 50000 users.\n",
      "Parsed 51000 users.\n",
      "Parsed 52000 users.\n",
      "Parsed 53000 users.\n",
      "Parsed 54000 users.\n",
      "Parsed 55000 users.\n",
      "Parsed 56000 users.\n",
      "Parsed 57000 users.\n",
      "Parsed 58000 users.\n",
      "Parsed 59000 users.\n",
      "Parsed 60000 users.\n",
      "Parsed 61000 users.\n",
      "Parsed 62000 users.\n",
      "Parsed 63000 users.\n",
      "Parsed 64000 users.\n",
      "Parsed 65000 users.\n",
      "Parsed 66000 users.\n",
      "Parsed 67000 users.\n",
      "Parsed 68000 users.\n",
      "Parsed 69000 users.\n",
      "Parsed 70000 users.\n",
      "Parsed 71000 users.\n",
      "Parsed 72000 users.\n",
      "Parsed 73000 users.\n",
      "Parsed 74000 users.\n",
      "Parsed 75000 users.\n",
      "Parsed 76000 users.\n",
      "Parsed 77000 users.\n",
      "Parsed 78000 users.\n",
      "Parsed 79000 users.\n",
      "Parsed 80000 users.\n",
      "Parsed 81000 users.\n",
      "Parsed 82000 users.\n",
      "Parsed 83000 users.\n",
      "Parsed 84000 users.\n",
      "Parsed 85000 users.\n",
      "Parsed 86000 users.\n",
      "Parsed 87000 users.\n",
      "Parsed 88000 users.\n",
      "Parsed 89000 users.\n",
      "Parsed 90000 users.\n",
      "Parsed 91000 users.\n",
      "Parsed 92000 users.\n",
      "Parsed 93000 users.\n",
      "Parsed 94000 users.\n",
      "Parsed 95000 users.\n",
      "Parsed 96000 users.\n",
      "Parsed 97000 users.\n",
      "Parsed 98000 users.\n",
      "Parsed 99000 users.\n",
      "Parsed 100000 users.\n",
      "Parsed 101000 users.\n",
      "Parsed 102000 users.\n",
      "Parsed 103000 users.\n",
      "Parsed 104000 users.\n",
      "Parsed 105000 users.\n",
      "Parsed 106000 users.\n",
      "Parsed 107000 users.\n",
      "Parsed 108000 users.\n",
      "Parsed 109000 users.\n",
      "Parsed 110000 users.\n",
      "Parsed 111000 users.\n",
      "Parsed 112000 users.\n",
      "Parsed 113000 users.\n",
      "Parsed 114000 users.\n",
      "Parsed 115000 users.\n",
      "Parsed 116000 users.\n",
      "Parsed 117000 users.\n",
      "Parsed 118000 users.\n",
      "Parsed 119000 users.\n",
      "Parsed 120000 users.\n",
      "Parsed 121000 users.\n",
      "Parsed 122000 users.\n",
      "Parsed 123000 users.\n",
      "Parsed 124000 users.\n",
      "Parsed 125000 users.\n",
      "Parsed 126000 users.\n",
      "Parsed 127000 users.\n",
      "Parsed 128000 users.\n",
      "Parsed 129000 users.\n",
      "Parsed 130000 users.\n",
      "Parsed 131000 users.\n",
      "Parsed 132000 users.\n",
      "Parsed 133000 users.\n",
      "Parsed 134000 users.\n",
      "Parsed 135000 users.\n",
      "Parsed 136000 users.\n",
      "Parsed 137000 users.\n",
      "Parsed 138000 users.\n",
      "Parsed 139000 users.\n",
      "Parsed 140000 users.\n",
      "Parsed 141000 users.\n",
      "Parsed 142000 users.\n",
      "Parsed 143000 users.\n",
      "Parsed 144000 users.\n",
      "Parsed 145000 users.\n",
      "Parsed 146000 users.\n",
      "Parsed 147000 users.\n",
      "Parsed 148000 users.\n",
      "Parsed 149000 users.\n",
      "Parsed 150000 users.\n",
      "Parsed 151000 users.\n",
      "Parsed 152000 users.\n",
      "Parsed 153000 users.\n",
      "Parsed 154000 users.\n",
      "Parsed 155000 users.\n",
      "Parsed 156000 users.\n",
      "Parsed 157000 users.\n",
      "Parsed 158000 users.\n",
      "Parsed 159000 users.\n",
      "Parsed 160000 users.\n",
      "Parsed 161000 users.\n",
      "Parsed 162000 users.\n",
      "Parsed 163000 users.\n",
      "Parsed 164000 users.\n",
      "Parsed 165000 users.\n",
      "Parsed 166000 users.\n",
      "Parsed 167000 users.\n",
      "Parsed 168000 users.\n",
      "Parsed 169000 users.\n",
      "Parsed 170000 users.\n",
      "Parsed 171000 users.\n",
      "Parsed 172000 users.\n",
      "Parsed 173000 users.\n",
      "Parsed 174000 users.\n",
      "Parsed 175000 users.\n",
      "Parsed 176000 users.\n",
      "Parsed 177000 users.\n",
      "Parsed 178000 users.\n",
      "Parsed 179000 users.\n",
      "Parsed 180000 users.\n",
      "Parsed 181000 users.\n",
      "Parsed 182000 users.\n",
      "Parsed 183000 users.\n",
      "Parsed 184000 users.\n",
      "Parsed 185000 users.\n",
      "Parsed 186000 users.\n",
      "Parsed 187000 users.\n",
      "Parsed 188000 users.\n",
      "Parsed 189000 users.\n",
      "Parsed 190000 users.\n",
      "Parsed 191000 users.\n",
      "Parsed 192000 users.\n",
      "Parsed 193000 users.\n",
      "Parsed 194000 users.\n",
      "Parsed 195000 users.\n",
      "Parsed 196000 users.\n",
      "Parsed 197000 users.\n",
      "Parsed 198000 users.\n",
      "Parsed 199000 users.\n",
      "Parsed 200000 users.\n",
      "Parsed 201000 users.\n",
      "Parsed 202000 users.\n",
      "Parsed 203000 users.\n",
      "Parsed 204000 users.\n",
      "Parsed 205000 users.\n",
      "Parsed 206000 users.\n",
      "Parsed 207000 users.\n",
      "Parsed 208000 users.\n",
      "Parsed 209000 users.\n",
      "Parsed 210000 users.\n",
      "Parsed 211000 users.\n",
      "Parsed 212000 users.\n",
      "Parsed 213000 users.\n",
      "Parsed 214000 users.\n",
      "Parsed 215000 users.\n",
      "Parsed 216000 users.\n",
      "Parsed 217000 users.\n",
      "Parsed 218000 users.\n",
      "Parsed 219000 users.\n",
      "Parsed 220000 users.\n",
      "Parsed 221000 users.\n",
      "Parsed 222000 users.\n",
      "Parsed 223000 users.\n",
      "Parsed 224000 users.\n",
      "Parsed 225000 users.\n",
      "Parsed 226000 users.\n",
      "Parsed 227000 users.\n",
      "Parsed 228000 users.\n",
      "Parsed 229000 users.\n",
      "Parsed 230000 users.\n",
      "Parsed 231000 users.\n",
      "Parsed 232000 users.\n",
      "Parsed 233000 users.\n",
      "Parsed 234000 users.\n",
      "Parsed 235000 users.\n",
      "Parsed 236000 users.\n",
      "Parsed 237000 users.\n",
      "Parsed 238000 users.\n",
      "Parsed 239000 users.\n",
      "Parsed 240000 users.\n",
      "Parsed 241000 users.\n",
      "Parsed 242000 users.\n",
      "Parsed 243000 users.\n",
      "Parsed 244000 users.\n",
      "Parsed 245000 users.\n",
      "Parsed 246000 users.\n",
      "Parsed 247000 users.\n",
      "Parsed 248000 users.\n",
      "Parsed 249000 users.\n",
      "Parsed 250000 users.\n",
      "Parsed 251000 users.\n",
      "Parsed 252000 users.\n",
      "Parsed 253000 users.\n",
      "Parsed 254000 users.\n",
      "Parsed 255000 users.\n",
      "Parsed 256000 users.\n",
      "Parsed 257000 users.\n",
      "Parsed 258000 users.\n",
      "Parsed 259000 users.\n",
      "Parsed 260000 users.\n",
      "Parsed 261000 users.\n",
      "Parsed 262000 users.\n",
      "Parsed 263000 users.\n",
      "Parsed 264000 users.\n",
      "Parsed 265000 users.\n",
      "Parsed 266000 users.\n",
      "Parsed 267000 users.\n",
      "Parsed 268000 users.\n",
      "Parsed 269000 users.\n",
      "Parsed 270000 users.\n",
      "Parsed 271000 users.\n",
      "Parsed 272000 users.\n",
      "Parsed 273000 users.\n",
      "Parsed 274000 users.\n",
      "Parsed 275000 users.\n",
      "Parsed 276000 users.\n",
      "Parsed 277000 users.\n",
      "Parsed 278000 users.\n",
      "Parsed 279000 users.\n",
      "Parsed 280000 users.\n",
      "Parsed 281000 users.\n",
      "Parsed 282000 users.\n",
      "Parsed 283000 users.\n",
      "Parsed 284000 users.\n",
      "Parsed 285000 users.\n",
      "Parsed 286000 users.\n",
      "Parsed 287000 users.\n",
      "Parsed 288000 users.\n",
      "Parsed 289000 users.\n",
      "Parsed 290000 users.\n",
      "Parsed 291000 users.\n",
      "Parsed 292000 users.\n",
      "Parsed 293000 users.\n",
      "Parsed 294000 users.\n",
      "Parsed 295000 users.\n",
      "Parsed 296000 users.\n",
      "Parsed 297000 users.\n",
      "Parsed 298000 users.\n",
      "Parsed 299000 users.\n",
      "Parsed 300000 users.\n",
      "Parsed 301000 users.\n",
      "Parsed 302000 users.\n",
      "Parsed 303000 users.\n",
      "Parsed 304000 users.\n",
      "Parsed 305000 users.\n",
      "Parsed 306000 users.\n",
      "Parsed 307000 users.\n",
      "Parsed 308000 users.\n",
      "Parsed 309000 users.\n",
      "Parsed 310000 users.\n",
      "Parsed 311000 users.\n",
      "Parsed 312000 users.\n",
      "Parsed 313000 users.\n",
      "Parsed 314000 users.\n",
      "Parsed 315000 users.\n",
      "Parsed 316000 users.\n",
      "Parsed 317000 users.\n",
      "Parsed 318000 users.\n",
      "Parsed 319000 users.\n",
      "Parsed 320000 users.\n",
      "Parsed 321000 users.\n",
      "Parsed 322000 users.\n",
      "Parsed 323000 users.\n",
      "Parsed 324000 users.\n",
      "Parsed 325000 users.\n",
      "Parsed 326000 users.\n",
      "Parsed 327000 users.\n",
      "Parsed 328000 users.\n",
      "Parsed 329000 users.\n",
      "Parsed 330000 users.\n",
      "Parsed 331000 users.\n",
      "Parsed 332000 users.\n",
      "Parsed 333000 users.\n",
      "Parsed 334000 users.\n",
      "Parsed 335000 users.\n",
      "Parsed 336000 users.\n",
      "Parsed 337000 users.\n",
      "Parsed 338000 users.\n",
      "Parsed 339000 users.\n",
      "Parsed 340000 users.\n",
      "Parsed 341000 users.\n",
      "Parsed 342000 users.\n",
      "Parsed 343000 users.\n",
      "Parsed 344000 users.\n",
      "Parsed 345000 users.\n",
      "Parsed 346000 users.\n",
      "Parsed 347000 users.\n",
      "Parsed 348000 users.\n",
      "Parsed 349000 users.\n",
      "Parsed 350000 users.\n",
      "Parsed 351000 users.\n",
      "Parsed 352000 users.\n",
      "Parsed 353000 users.\n",
      "Parsed 354000 users.\n",
      "Parsed 355000 users.\n",
      "Parsed 356000 users.\n",
      "Parsed 357000 users.\n",
      "Parsed 358000 users.\n",
      "Parsed 359000 users.\n",
      "Parsed 360000 users.\n",
      "Parsed 361000 users.\n",
      "Parsed 362000 users.\n",
      "Parsed 363000 users.\n",
      "Parsed 364000 users.\n",
      "Parsed 365000 users.\n",
      "Parsed 366000 users.\n",
      "Parsed 367000 users.\n",
      "Parsed 368000 users.\n",
      "Parsed 369000 users.\n",
      "Parsed 370000 users.\n",
      "Parsed 371000 users.\n",
      "Parsed 372000 users.\n",
      "Parsed 373000 users.\n",
      "Parsed 374000 users.\n",
      "Parsed 375000 users.\n",
      "Parsed 376000 users.\n",
      "Parsed 377000 users.\n",
      "Parsed 378000 users.\n",
      "Parsed 379000 users.\n",
      "Parsed 380000 users.\n",
      "Parsed 381000 users.\n",
      "Parsed 382000 users.\n",
      "Parsed 383000 users.\n",
      "Parsed 384000 users.\n",
      "Parsed 385000 users.\n",
      "Parsed 386000 users.\n",
      "Parsed 387000 users.\n",
      "Parsed 388000 users.\n",
      "Parsed 389000 users.\n",
      "Parsed 390000 users.\n",
      "Parsed 391000 users.\n",
      "Parsed 392000 users.\n",
      "Parsed 393000 users.\n",
      "Parsed 394000 users.\n",
      "Parsed 395000 users.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 396000 users.\n",
      "Parsed 397000 users.\n",
      "Parsed 398000 users.\n",
      "Parsed 399000 users.\n",
      "Parsed 400000 users.\n",
      "Parsed 401000 users.\n",
      "Parsed 402000 users.\n",
      "Parsed 403000 users.\n",
      "Parsed 404000 users.\n",
      "Parsed 405000 users.\n",
      "Parsed 406000 users.\n",
      "Parsed 407000 users.\n",
      "Parsed 408000 users.\n",
      "Parsed 409000 users.\n",
      "Parsed 410000 users.\n",
      "Parsed 411000 users.\n",
      "Parsed 412000 users.\n",
      "Parsed 413000 users.\n",
      "Parsed 414000 users.\n",
      "Parsed 415000 users.\n",
      "Parsed 416000 users.\n",
      "Parsed 417000 users.\n",
      "Parsed 418000 users.\n",
      "Parsed 419000 users.\n",
      "Parsed 420000 users.\n",
      "Parsed 421000 users.\n",
      "Parsed 422000 users.\n",
      "Parsed 423000 users.\n",
      "Parsed 424000 users.\n",
      "Parsed 425000 users.\n",
      "Parsed 426000 users.\n",
      "Parsed 427000 users.\n",
      "Parsed 428000 users.\n",
      "Parsed 429000 users.\n",
      "Parsed 430000 users.\n",
      "Parsed 431000 users.\n",
      "Parsed 432000 users.\n",
      "Parsed 433000 users.\n",
      "Parsed 434000 users.\n",
      "Parsed 435000 users.\n",
      "Parsed 436000 users.\n",
      "Parsed 437000 users.\n",
      "Parsed 438000 users.\n",
      "Parsed 439000 users.\n",
      "Parsed 440000 users.\n",
      "Parsed 441000 users.\n",
      "Parsed 442000 users.\n",
      "Parsed 443000 users.\n",
      "Parsed 444000 users.\n",
      "Parsed 445000 users.\n",
      "Parsed 446000 users.\n",
      "Parsed 447000 users.\n",
      "Parsed 448000 users.\n",
      "Parsed 449000 users.\n",
      "Parsed 450000 users.\n",
      "Parsed 451000 users.\n",
      "Parsed 452000 users.\n",
      "Parsed 453000 users.\n",
      "Parsed 454000 users.\n",
      "Parsed 455000 users.\n",
      "Parsed 456000 users.\n",
      "Parsed 457000 users.\n",
      "Parsed 458000 users.\n",
      "Parsed 459000 users.\n",
      "Parsed 460000 users.\n",
      "Parsed 461000 users.\n",
      "Parsed 462000 users.\n",
      "Parsed 463000 users.\n",
      "Parsed 464000 users.\n",
      "Parsed 465000 users.\n",
      "Parsed 466000 users.\n",
      "Parsed 467000 users.\n",
      "Parsed 468000 users.\n",
      "Parsed 469000 users.\n",
      "Parsed 470000 users.\n",
      "Parsed 471000 users.\n",
      "Parsed 472000 users.\n",
      "Parsed 473000 users.\n",
      "Parsed 474000 users.\n",
      "Parsed 475000 users.\n",
      "Parsed 476000 users.\n",
      "Parsed 477000 users.\n",
      "Parsed 478000 users.\n",
      "Parsed 479000 users.\n",
      "Parsed 480000 users.\n",
      "Parsed 481000 users.\n",
      "Parsed 482000 users.\n",
      "Parsed 483000 users.\n",
      "Parsed 484000 users.\n",
      "Parsed 485000 users.\n",
      "Parsed 486000 users.\n",
      "Parsed 487000 users.\n",
      "Parsed 488000 users.\n",
      "Parsed 489000 users.\n",
      "Parsed 490000 users.\n",
      "Parsed 491000 users.\n",
      "Parsed 492000 users.\n",
      "Parsed 493000 users.\n",
      "Parsed 494000 users.\n",
      "Parsed 495000 users.\n",
      "Parsed 496000 users.\n",
      "Parsed 497000 users.\n",
      "Parsed 498000 users.\n",
      "Parsed 499000 users.\n",
      "Parsed 500000 users.\n",
      "Parsed 501000 users.\n",
      "Parsed 502000 users.\n",
      "Parsed 503000 users.\n",
      "Parsed 504000 users.\n",
      "Parsed 505000 users.\n",
      "Parsed 506000 users.\n",
      "Parsed 507000 users.\n",
      "Parsed 508000 users.\n",
      "Parsed 509000 users.\n",
      "Parsed 510000 users.\n",
      "Parsed 511000 users.\n",
      "Parsed 512000 users.\n",
      "Parsed 513000 users.\n",
      "Parsed 514000 users.\n",
      "Parsed 515000 users.\n",
      "Parsed 516000 users.\n",
      "Parsed 517000 users.\n",
      "Parsed 518000 users.\n",
      "Parsed 519000 users.\n",
      "Parsed 520000 users.\n",
      "Parsed 521000 users.\n",
      "Parsed 522000 users.\n",
      "Parsed 523000 users.\n",
      "Parsed 524000 users.\n",
      "Parsed 525000 users.\n",
      "Parsed 526000 users.\n",
      "Parsed 527000 users.\n",
      "Parsed 528000 users.\n",
      "Parsed 529000 users.\n",
      "Parsed 530000 users.\n",
      "Parsed 531000 users.\n",
      "Parsed 532000 users.\n",
      "Parsed 533000 users.\n",
      "Parsed 534000 users.\n",
      "Parsed 535000 users.\n",
      "Parsed 536000 users.\n",
      "Parsed 537000 users.\n",
      "Parsed 538000 users.\n",
      "Parsed 539000 users.\n",
      "Parsed 540000 users.\n",
      "Parsed 541000 users.\n",
      "Parsed 542000 users.\n",
      "Parsed 543000 users.\n",
      "Parsed 544000 users.\n",
      "Parsed 545000 users.\n",
      "Parsed 546000 users.\n",
      "Parsed 547000 users.\n",
      "Parsed 548000 users.\n",
      "Parsed 549000 users.\n",
      "Parsed 550000 users.\n",
      "Parsed 551000 users.\n",
      "Parsed 552000 users.\n",
      "Parsed 553000 users.\n",
      "Parsed 554000 users.\n",
      "Parsed 555000 users.\n",
      "Parsed 556000 users.\n",
      "Parsed 557000 users.\n",
      "Parsed 558000 users.\n",
      "Parsed 559000 users.\n",
      "Parsed 560000 users.\n",
      "Parsed 561000 users.\n",
      "Parsed 562000 users.\n",
      "Parsed 563000 users.\n",
      "Parsed 564000 users.\n",
      "Parsed 565000 users.\n",
      "Parsed 566000 users.\n",
      "Parsed 567000 users.\n",
      "Parsed 568000 users.\n",
      "Parsed 569000 users.\n",
      "Parsed 570000 users.\n",
      "Parsed 571000 users.\n",
      "Parsed 572000 users.\n",
      "Parsed 573000 users.\n",
      "Parsed 574000 users.\n",
      "Parsed 575000 users.\n",
      "Parsed 576000 users.\n",
      "Parsed 577000 users.\n",
      "Parsed 578000 users.\n",
      "Parsed 579000 users.\n",
      "Parsed 580000 users.\n",
      "Parsed 581000 users.\n",
      "Parsed 582000 users.\n",
      "Parsed 583000 users.\n",
      "Parsed 584000 users.\n",
      "Parsed 585000 users.\n",
      "Parsed 586000 users.\n",
      "Parsed 587000 users.\n",
      "Parsed 588000 users.\n",
      "Parsed 589000 users.\n",
      "Parsed 590000 users.\n",
      "Parsed 591000 users.\n",
      "Parsed 592000 users.\n",
      "Parsed 593000 users.\n",
      "Parsed 594000 users.\n",
      "Parsed 595000 users.\n",
      "Parsed 596000 users.\n",
      "Parsed 597000 users.\n",
      "Parsed 598000 users.\n",
      "Parsed 599000 users.\n",
      "Parsed 600000 users.\n",
      "Parsed 601000 users.\n",
      "Parsed 602000 users.\n",
      "Parsed 603000 users.\n",
      "Parsed 604000 users.\n",
      "Parsed 605000 users.\n",
      "Parsed 606000 users.\n",
      "Parsed 607000 users.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-d51980df4e2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m \u001b[0;32min\u001b[0m \u001b[0musers_to_predict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     _, hotel_clusters = index(queries={'user_id':tf.constant([str(user['user_id'])]), \n\u001b[1;32m      5\u001b[0m                                        'is_package': tf.constant([user['is_package']])})\n",
      "\u001b[0;32m~/miniconda3/envs/recommender/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36miterrows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/recommender/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    325\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/recommender/lib/python3.7/site-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[0;31m# extract ndarray or ExtensionArray, ensure we have no PandasArray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;31m# GH#846\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/recommender/lib/python3.7/site-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36mextract_array\u001b[0;34m(obj, extract_numpy)\u001b[0m\n\u001b[1;32m    379\u001b[0m     \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \"\"\"\n\u001b[0;32m--> 381\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mABCIndexClass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for i, user in users_to_predict.iterrows():\n",
    "    _, hotel_clusters = index(queries={'user_id':tf.constant([str(user['user_id'])]), \n",
    "                                       'is_package': tf.constant([user['is_package']])})\n",
    "    results.append({'user_id': user['user_id'], 'hotel cluster' : [int(i) for i in hotel_clusters[0, :5].numpy()]})\n",
    "    if i % 1_000 == 0:\n",
    "        print(f\"Parsed {i} users.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv('results_607000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"results_607_000.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recommender (Python=3.7)",
   "language": "python",
   "name": "recommender"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "268.8px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
