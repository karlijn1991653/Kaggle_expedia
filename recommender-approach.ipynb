{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xpedia \n",
    "\n",
    "Your goal of this competition is to predict the booking outcome (hotel cluster) for a user event, based on their search and other attributes associated with that user event. Expedia is interested in predicting which hotel group a user is going to book. Expedia has in-house algorithms to form hotel clusters, where similar hotels for a search (based on historical price, customer star ratings, geographical locations relative to city center, etc) are grouped together.\n",
    "\n",
    "### MVP3:\n",
    " - Recommender\n",
    " - Investigate how to use a recommender system for this problem\n",
    "  * collaborative filtering (on user or item level)\n",
    "  * hybrid model combining use clicks/booking data & search features\n",
    "\n",
    "\n",
    "https://www.kaggle.com/c/expedia-hotel-recommendations/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', None) \n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './expedia-hotel-recommendations/'\n",
    "\n",
    "destinations = pd.read_csv(data_dir + 'destinations.csv')\n",
    "train = pd.read_csv(data_dir + 'train.csv')\n",
    "train_bookings = train[train['is_booking'] == 1]\n",
    "test = pd.read_csv(data_dir + 'test.csv')\n",
    "sample_submission = pd.read_csv(data_dir + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = train.sample(500000)\n",
    "train_sample.to_csv(data_dir + './train_sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Pure) collaborative filtering\n",
    "\n",
    "https://realpython.com/build-recommendation-engine-collaborative-filtering/\n",
    "\n",
    "To build a system that can automatically recommend items to users based on the preferences of other users, the first step is to find similar users or items. The second step is to predict the ratings of the items that are not yet rated by a user. So, you will need the answers to these questions:\n",
    "\n",
    "How do you determine which users or items are similar to one another?\n",
    "Given that you know which users are similar, how do you determine the rating that a user would give to an item based on the ratings of similar users?\n",
    "How do you measure the accuracy of the ratings you calculate?\n",
    "\n",
    "* https://towardsdatascience.com/prototyping-a-recommender-system-step-by-step-part-1-knn-item-based-collaborative-filtering-637969614ea\n",
    "\n",
    "* https://towardsdatascience.com/prototyping-a-recommender-system-step-by-step-part-2-alternating-least-square-als-matrix-4a76c58714a1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "test_threshold = \"2014-10-01\"\n",
    "\n",
    "# Start only with bookings only : note, if we want to include clicks, we need to filter the clicks from the\n",
    "# validation split\n",
    "train_set = train_bookings[train_bookings['date_time'] < test_threshold]\n",
    "test_set = train_bookings[train_bookings['date_time'] >= test_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feedback_matrix(df, n_clusters=100):\n",
    "    \n",
    "    user_bookings = (df[['user_id', 'hotel_cluster']]\n",
    "                     .groupby('user_id')\n",
    "                     .agg({'hotel_cluster': list})\n",
    "                     .reset_index())\n",
    "    \n",
    "    n_users = len(set(df['user_id']))\n",
    "    \n",
    "    # Fill feedback matrix\n",
    "    feedback = np.zeros([n_users, n_clusters])\n",
    "    for user in user_bookings.index:\n",
    "        feedback[user, user_bookings.loc[user, 'hotel_cluster']] = 1\n",
    "        \n",
    "    return feedback\n",
    "\n",
    "def create_y(df): \n",
    "    y_tmp = df.groupby('user_id').agg({'hotel_cluster': list})['hotel_cluster'].values\n",
    "\n",
    "    return [\n",
    "        y_i for y_i in y_tmp\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(704207, 100)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = create_feedback_matrix(train_set)\n",
    "\n",
    "y_train = create_y(train_set)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(306682, 100)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = create_feedback_matrix(test_set)\n",
    "y_test = create_y(test_set)\n",
    "\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.decomposition import NMF\n",
    "from ml_metrics import mapk\n",
    "\n",
    "\n",
    "class ALS(BaseEstimator):\n",
    "    \n",
    "    def __init__(self, n_components=2, cutoff=5):\n",
    "        self.n_components = n_components\n",
    "        self.cutoff = cutoff\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \n",
    "        self._model = self._get_model()\n",
    "        \n",
    "        return self._model.fit(X)\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return self.model.transform(X)\n",
    "    \n",
    "    def predict(self, X):\n",
    "\n",
    "        W = self._model.fit_transform(X)\n",
    "        H = self._model.components_\n",
    "        V = np.dot(W, H)\n",
    "        \n",
    "        return np.argpartition(V, -self.cutoff)[:, -self.cutoff:]\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        \"\"\" TODO creates a prediction per user instead of per search query. \"\"\"\n",
    "        predictions = self.predict(X)\n",
    "        return mapk(actual=y, predicted=predictions, k=self.cutoff)\n",
    "    \n",
    "    def _get_model(self):\n",
    "        return NMF(\n",
    "            n_components=self.n_components, \n",
    "            init='random', random_state=0, max_iter=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_components</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.17724</td>\n",
       "      <td>0.11843</td>\n",
       "      <td>9.57038</td>\n",
       "      <td>2.83471</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_components': 10}</td>\n",
       "      <td>0.17007</td>\n",
       "      <td>0.17168</td>\n",
       "      <td>0.17087</td>\n",
       "      <td>0.00081</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.09748</td>\n",
       "      <td>1.78384</td>\n",
       "      <td>8.65820</td>\n",
       "      <td>1.09230</td>\n",
       "      <td>5</td>\n",
       "      <td>{'n_components': 5}</td>\n",
       "      <td>0.13781</td>\n",
       "      <td>0.13739</td>\n",
       "      <td>0.13760</td>\n",
       "      <td>0.00021</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "1        9.17724       0.11843          9.57038         2.83471   \n",
       "0        8.09748       1.78384          8.65820         1.09230   \n",
       "\n",
       "  param_n_components                params  split0_test_score  \\\n",
       "1                 10  {'n_components': 10}            0.17007   \n",
       "0                  5   {'n_components': 5}            0.13781   \n",
       "\n",
       "   split1_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "1            0.17168          0.17087         0.00081                1  \n",
       "0            0.13739          0.13760         0.00021                2  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "\n",
    "param_search = {\n",
    "    'n_components' : [5, 10]\n",
    "}\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=2)\n",
    "gsearch = GridSearchCV(estimator=ALS(), cv=tscv,\n",
    "                       param_grid=param_search)\n",
    "\n",
    "gsearch.fit(X_train, y_train)\n",
    "\n",
    "pd.DataFrame(gsearch.cv_results_).sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = gsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAP at K: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.15138185934906156"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Test MAP at K: \")\n",
    "\n",
    "estimator.score(X=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "https://github.com/benhamner/Metrics/blob/master/Python/ml_metrics/average_precision.py\n",
    "\n",
    "Is it correct that 'trailing' wrong predictions do not harm the average precision?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Mean Average Precision at K: \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-99ca6f48841c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mactual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hotel_cluster'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmapk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "from ml_metrics import apk, mapk\n",
    "print(\"Train Mean Average Precision at K: \")\n",
    "\n",
    "actual = train_set['hotel_cluster'].values.reshape(-1, 1)\n",
    "\n",
    "mapk(actual=actual, predicted=predictions, k=cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Mean Average Precisioon at K: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.044222090713400726"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Validation Mean Average Precisioon at K: \")\n",
    "\n",
    "actual = validation_set['hotel_cluster'].values.reshape(-1, 1)\n",
    "\n",
    "mapk(actual=actual, predicted=predictions, k=cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apk(actual=[5], predicted=[2, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apk(actual=[5], predicted=[5, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({95: 159973, 48: 170061, 59: 148190, 42: 48789, 91: 50895})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(np.argmax(V, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import non_negative_factorization\n",
    "\n",
    "W, H, n_iter = non_negative_factorization(feedback, n_components=2, solver='cd', init='random', random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS Explore\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.non_negative_factorization.html\n",
    "\n",
    "https://medium.com/logicai/non-negative-matrix-factorization-for-recommendation-systems-985ca8d5c16c\n",
    "\n",
    "Can we use the mechanism to prepare food recommendations for people? Yes, and itâ€™s easier than you may think. By multiplying W and H, we obtain initial V matrix approximation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "als_model = NMF(n_components=2, init='random', random_state=0)\n",
    "\n",
    "W = als_model.fit_transform(train_feedback)\n",
    "H = als_model.components_\n",
    "\n",
    "V = np.dot(W, H)\n",
    "V.shape\n",
    "\n",
    "cutoff = 5\n",
    "\n",
    "predictions = np.argpartition(V, -cutoff)[:, -cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(577908, 5)\n",
      "(5, 100)\n"
     ]
    }
   ],
   "source": [
    "print(W.shape) \n",
    "print(H.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [    0     1     2 ... 96315 96316 96317] TEST: [ 96318  96319  96320 ... 192633 192634 192635]\n",
      "TRAIN: [     0      1      2 ... 192633 192634 192635] TEST: [192636 192637 192638 ... 288951 288952 288953]\n",
      "TRAIN: [     0      1      2 ... 288951 288952 288953] TEST: [288954 288955 288956 ... 385269 385270 385271]\n",
      "TRAIN: [     0      1      2 ... 385269 385270 385271] TEST: [385272 385273 385274 ... 481587 481588 481589]\n",
      "TRAIN: [     0      1      2 ... 481587 481588 481589] TEST: [481590 481591 481592 ... 577905 577906 577907]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "\n",
    "X = train_feedback\n",
    "\n",
    "tscv = TimeSeriesSplit()\n",
    "\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
